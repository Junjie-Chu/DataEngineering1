{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "applicable-planner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "processed-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",3)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.cores.max\",4)\\\n",
    "        .appName(\"JunjieChuA3PartB\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "advance-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.1 and B.2\n",
    "data_frame = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv('hdfs://192.168.2.113:9000/parking-citations.csv')\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "shared-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "|Ticket number|         Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|          Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "|   1103341116|2015-12-21T00:00:00|      1251|    null|       null|            CA|           200304|null|HOND|        PA|   GY|   13147 WELBY WAY|01521|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1103700150|2015-12-21T00:00:00|      1435|    null|       null|            CA|           201512|null| GMC|        VN|   WH|     525 S MAIN ST| 1C51|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1104803000|2015-12-21T00:00:00|      2055|    null|       null|            CA|           201503|null|NISS|        PA|   BK|     200 WORLD WAY|  2R2|     2|          8939|           WHITE CURB|         58|6439997.9|1802686.4|\n",
      "|   1104820732|2015-12-26T00:00:00|      1515|    null|       null|            CA|             null|null|ACUR|        PA|   WH|     100 WORLD WAY| 2F11|     2|           000|               17104h|       null|6440041.1|1802686.2|\n",
      "|   1105461453|2015-09-15T00:00:00|       115|    null|       null|            CA|           200316|null|CHEV|        PA|   BK|GEORGIA ST/OLYMPIC|1FB70|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_frame.show(5)\n",
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "radical-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9257460\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#B.3 and B.4\n",
    "print(data_frame.count())\n",
    "#result 9257460\n",
    "print(data_frame.rdd.getNumPartitions())\n",
    "#result 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arbitrary-partition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Ticket number='1103341116', Issue Date='2015-12-21T00:00:00', Issue time='1251', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date='200304', Make='HOND', Body Style='PA', Color='GY', Location='13147 WELBY WAY', Route='01521', Agency='1', Violation code='4000A1', Violation Description='NO EVIDENCE OF REG', Fine amount='50'),\n",
       " Row(Ticket number='1103700150', Issue Date='2015-12-21T00:00:00', Issue time='1435', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date='201512', Make='GMC', Body Style='VN', Color='WH', Location='525 S MAIN ST', Route='1C51', Agency='1', Violation code='4000A1', Violation Description='NO EVIDENCE OF REG', Fine amount='50'),\n",
       " Row(Ticket number='1104803000', Issue Date='2015-12-21T00:00:00', Issue time='2055', Meter Id=None, Marked Time=None, RP State Plate='CA', Plate Expiry Date='201503', Make='NISS', Body Style='PA', Color='BK', Location='200 WORLD WAY', Route='2R2', Agency='2', Violation code='8939', Violation Description='WHITE CURB', Fine amount='58')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B.5\n",
    "df = data_frame.drop('VIN').drop('Latitude').drop('Longitude')\n",
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handmade-booth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(Fine amount='50', float Fine amount=50.0), Row(Fine amount='50', float Fine amount=50.0), Row(Fine amount='58', float Fine amount=58.0), Row(Fine amount=None, float Fine amount=0.0), Row(Fine amount='93', float Fine amount=93.0)]\n",
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- float Fine amount: float (nullable = true)\n",
      "\n",
      "Show the max value:\n",
      "505.0\n",
      "Show the number of max value:\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#B.6\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def string_to_float(x):\n",
    "    if x is None:\n",
    "        x = 0.0\n",
    "    return float(x)\n",
    "\n",
    "udfstring_to_float = udf(string_to_float, StringType())\n",
    "dfnew = df.withColumn(\"float Fine amount\",udfstring_to_float(\"Fine amount\").cast('float'))\n",
    "\n",
    "#check if all the empty values are 0 now\n",
    "print(dfnew.select(\"Fine amount\",\"float Fine amount\").take(5))\n",
    "#check the types of schema\n",
    "dfnew.printSchema()\n",
    "#find the max value \n",
    "max_value = dfnew.agg({\"float Fine amount\": \"max\"}).collect()[0][0]\n",
    "print(\"Show the max value:\")\n",
    "print(max_value)\n",
    "#count the number of max\n",
    "print(\"Show the number of max value:\")\n",
    "print(dfnew.where(dfnew['float Fine amount'] == max_value).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.7\n",
    "sums = dfnew.select('Make').count()\n",
    "make = dfnew.select('Make').groupby(dfnew['Make']).count().orderBy('count', ascending=False)\n",
    "make = make.withColumn(\"frequency\",make['count']/sums)\n",
    "make.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.8\n",
    "from pyspark.sql.functions import col, create_map, lit\n",
    "from pyspark.sql.functions import coalesce\n",
    "from itertools import chain\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "COLORS = { 'AL':'Aluminum', 'AM':'Amber', 'BG':'Beige', 'BK':'Black', 'BL':'Blue', 'BN':'Brown', 'BR':'Brown', 'BZ':'Bronze', 'CH':'Charcoal', 'DK':'Dark', 'GD':'Gold', 'GO':'Gold', 'GN':'Green', 'GY':'Gray', 'GT':'Granite', 'IV':'Ivory', 'LT':'Light', 'OL':'Olive', 'OR':'Orange', 'MR':'Maroon', 'PK':'Pink', 'RD':'Red', 'RE':'Red', 'SI':'Silver', 'SL':'Silver', 'SM':'Smoke', 'TN':'Tan', 'VT':'Violet', 'WT':'White', 'WH':'White', 'YL':'Yellow', 'YE':'Yellow', 'UN':'Unknown' }\n",
    "#COLORS is the dict, col is the key which comes from dataframe.color\n",
    "def transformcol(col):\n",
    "    if COLORS.get(col):\n",
    "        return COLORS.get(col)\n",
    "    else:\n",
    "        return col\n",
    "udftransformcol = udf(transformcol, StringType())\n",
    "dfnew = dfnew.withColumn(\"color_long\", udftransformcol(\"Color\"))\n",
    "\n",
    "print(\"Show the results:\")\n",
    "dfnew.select(\"Ticket number\",\"Color\",\"color_long\").show(5)\n",
    "print(\"Show the results of colors which are not in the dict:\")\n",
    "dfnew.filter(dfnew['color_long']==\"GR\").select(\"Ticket number\",\"Color\",\"color_long\").show(3)\n",
    "dfnew.filter(dfnew['color_long']==\"MA\").select(\"Ticket number\",\"Color\",\"color_long\").show(3)\n",
    "dfnew.filter(dfnew['color_long']==\"TA\").select(\"Ticket number\",\"Color\",\"color_long\").show(3)\n",
    "dfnew.filter(dfnew['color_long']==\"BU\").select(\"Ticket number\",\"Color\",\"color_long\").show(3)\n",
    "dfnew.filter(dfnew['color_long'].isNull()).select(\"Ticket number\",\"Color\",\"color_long\").show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B.9\n",
    "toyotacolor = dfnew.filter(dfnew['Make']==\"TOYT\").groupby(dfnew['color_long']).count().orderBy('count', ascending=False)\n",
    "toyotacolor = toyotacolor.withColumn('Make',lit('TOYT'))\n",
    "toyotacolor = toyotacolor.select(\"Make\",\"color_long\",\"count\")\n",
    "toyotacolor.show(20)\n",
    "mostcolor=toyotacolor.agg({\"count\": \"max\"}).collect()[0][0]\n",
    "toyotacolor.where(toyotacolor['count'] == mostcolor).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-daughter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
